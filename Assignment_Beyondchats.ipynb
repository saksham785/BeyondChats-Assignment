{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1599g9RuduXx",
    "outputId": "da6c2d13-d0c6-4d8a-f88b-48ffae720df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw beautifulsoup4 transformers torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9Scmo42orpk",
    "outputId": "4d1d5fe9-17e0-464b-bfed-5c5998067883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gD6ISdPueF1C",
    "outputId": "4937098b-540f-46c9-c6d1-d0460979d892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Reddit client_id: ··········\n",
      "Enter Reddit client_secret: ··········\n",
      "Enter Reddit user_agent: ··········\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"REDDIT_CLIENT_ID\"] = getpass(\"Enter Reddit client_id: \")\n",
    "os.environ[\"REDDIT_CLIENT_SECRET\"] = getpass(\"Enter Reddit client_secret: \")\n",
    "os.environ[\"REDDIT_USER_AGENT\"] = getpass(\"Enter Reddit user_agent: \")\n",
    "\n",
    "# Initialize Reddit with your app credentials\n",
    "def init_reddit():\n",
    "    return praw.Reddit(\n",
    "          client_id = os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "          client_secret = os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "          user_agent = os.getenv(\"REDDIT_USER_AGENT\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JN4zS3ssn7IW"
   },
   "outputs": [],
   "source": [
    "# Scrape Reddit user posts and comments\n",
    "def scrape_user_data(username, reddit):\n",
    "    user = reddit.redditor(username)\n",
    "    posts, comments = [], []\n",
    "\n",
    "    for submission in user.submissions.new(limit=100):\n",
    "        posts.append({'title': submission.title, 'body': submission.selftext, 'url': submission.url})\n",
    "\n",
    "    for comment in user.comments.new(limit=100):\n",
    "        comments.append({'body': comment.body, 'link': f\"https://reddit.com{comment.permalink}\"})\n",
    "\n",
    "    return posts, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Gk79TmnOdv9k"
   },
   "outputs": [],
   "source": [
    "# Use HuggingFace summarizer\n",
    "def summarize_text(text_chunks):\n",
    "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "    return [summarizer(chunk, max_length=60, min_length=20, do_sample=False)[0]['summary_text'] for chunk in tqdm(text_chunks)]\n",
    "\n",
    "# Build user persona from summaries\n",
    "def build_user_persona(posts, comments):\n",
    "    text_chunks, sources = [], []\n",
    "\n",
    "    for post in posts:\n",
    "        content = f\"{post['title']}\\n{post['body']}\"\n",
    "        if len(content) > 100:\n",
    "            text_chunks.append(content[:1024])\n",
    "            sources.append(post.get('url', ''))\n",
    "\n",
    "    for comment in comments:\n",
    "        body = comment['body']\n",
    "        if len(body) > 100:\n",
    "            text_chunks.append(body[:1024])\n",
    "            sources.append(comment['link'])\n",
    "\n",
    "    summaries = summarize_text(text_chunks)\n",
    "\n",
    "    persona = {\n",
    "        'Behavior Traits': [],\n",
    "        'Interests': [],\n",
    "        'Goals': [],\n",
    "        'Needs': [],\n",
    "        'Motivations': []\n",
    "    }\n",
    "\n",
    "    for i, summary in enumerate(summaries):\n",
    "        src = sources[i]\n",
    "        summary_lower = summary.lower()\n",
    "\n",
    "        if \"want\" in summary_lower or \"goal\" in summary_lower:\n",
    "            persona['Goals'].append((summary, src))\n",
    "        elif \"need\" in summary_lower:\n",
    "            persona['Needs'].append((summary, src))\n",
    "        elif \"enjoy\" in summary_lower or \"like\" in summary_lower:\n",
    "            persona['Interests'].append((summary, src))\n",
    "        elif \"feel\" in summary_lower or \"think\" in summary_lower:\n",
    "            persona['Behavior Traits'].append((summary, src))\n",
    "        else:\n",
    "            persona['Motivations'].append((summary, src))\n",
    "\n",
    "    return persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e3yzW4JBoAON"
   },
   "outputs": [],
   "source": [
    "# Save persona to text file\n",
    "def save_persona(username, persona):\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    filepath = f\"output/{username}_persona.txt\"\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for category, values in persona.items():\n",
    "            f.write(f\"\\n== {category} ==\\n\")\n",
    "            for value, source in values:\n",
    "                f.write(f\"- {value}\\n  [Source] {source}\\n\")\n",
    "    print(f\"\\n Persona saved to {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# Extract username from Reddit profile URL\n",
    "def extract_username_from_url(url):\n",
    "    return url.strip(\"/\").split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767,
     "referenced_widgets": [
      "c975a7e5f15744cfbfe96e1ebc65d275",
      "e82b800bf0214840876c06fb2bc4a3a3",
      "a6536aa01c344747850f75e6728f89c8",
      "0801b55075ec4c13ba862b413d6cae2e",
      "69d32e6cc69941acab5285874c3cd7cc",
      "d81246a2a88f47d4a657361471f313f2",
      "7fe0a5eb5ba14d49a1bc6bdbc9fc9b38",
      "3bc4d44fd3eb450babb84209260912f1",
      "e65df633fb3848a98a3297c0f0e03a49",
      "edb90988721844ffb8650c10d1bcd331",
      "e3e7ca36522045b0875636a3b75e4f8c",
      "23d9cb406a07422ba0d4c392b2da753d",
      "31c6086938ed44a08828748ed3a006c7",
      "a91617851b5a476ab9629378f2991810",
      "d724b4e6148247618a27ea1697289488",
      "e5697747754d493ebe52b42542340eb2",
      "b6535151e8974421ad9e155e5e175f8a",
      "c8de28d027ab47d785bff91e4b98e1c9",
      "8287834a73c74b09bf3a5c4b580bd40b",
      "b88aea9fca974c2c9152a97eede08f37",
      "cbcb3ffc68b7436aa66baa5f40ffe896",
      "2e4228ad8cf148d084ce0b97f2303725",
      "fc9c2f04677d44109e05a58162b18b2c",
      "87337f9c814f466d8bbca48392bfdc1e",
      "2f89e1e570b6445cb0ccafc81fcb8186",
      "bd6afd7a918f44c39eb8c7287a14f816",
      "216994ee180a49cf8bfdeef58ebde7d0",
      "a7680fe39221454680dbb3c422113f11",
      "60207aee1b144d0ba27d15c2bc9c6d44",
      "6957cb3a4c354b82b4b00a774b53340c",
      "68cd433bd4b64ede899fd50e08a20ab1",
      "ad98a84586a94f088c8edb881bfbef21",
      "b5efd443c10b4dd2aee5953c9e83d804",
      "8f54dee2fffe47518a7a9d0712086ccc",
      "c67f1689d5904f0c8a3841c595730ba4",
      "be7be944329d40aeadfc76b7f881579d",
      "5d754c63a03c4654a58d82dbf934ac92",
      "8ca50d9b1f8949d782c662759dac7878",
      "1e556ac4392e4928a33b17a3375cb73e",
      "e8af8a4df9d1479cb5e272ad49fc6159",
      "ec6f928f21e94b2d97a4b1d5fb32bcc5",
      "99503e7911a74703a7b7d5ac82664700",
      "05233aeba1d343f9807a273408d15e30",
      "7f30fe670f5f45118eac2712331d1673",
      "0ba79f3d01ec4c8fab242742a624d49e",
      "4253bdc8e33a4f86adb2e1d59860b241",
      "b986afe7076c4dbda632fa741dd0a763",
      "869f4c819c5045d9a33e28d09102c1b1",
      "53dc8745aeda45508b306dc12b11d1c4",
      "80747b9c10d7491c83bddd25e867820e",
      "0cf96eb8ba6c4550bcfdc4c49440e79c",
      "88b44f9b92eb4adab8a5d8c9a09c9ab4",
      "41e74f228efe4360937aaaf6d8484aed",
      "70d5bd1a75a34400b6dfc8efe56c3096",
      "62d3dee309b041088e9d294f13d9a93d",
      "071a5b6069b8447bab0156fdec753c71",
      "7865a5be4b55432f99b06f80050eeb74",
      "717550f58afa4a6383442543cf2339be",
      "6f683dd618644974aedea20eb9858581",
      "491c8522caa34e64b68371d17c060011",
      "b7b78c42d0014510ba71b6afc4729e59",
      "2728b12cea054b80983fc813470cff48",
      "3fb638ec232844658182e5253ba45d83",
      "c6c5222066794f70a2b0c2ac483a2123",
      "7ea43dd26baa47d19a9b088b4581cd7c",
      "6c971caa107f41b99fbc66589deb2db9"
     ]
    },
    "id": "-HV0l0L4mIOQ",
    "outputId": "60b98b2c-1364-4cbb-eda9-2fdf3575a0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for: Hungry-Move-6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating persona...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c975a7e5f15744cfbfe96e1ebc65d275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d9cb406a07422ba0d4c392b2da753d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9c2f04677d44109e05a58162b18b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f54dee2fffe47518a7a9d0712086ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba79f3d01ec4c8fab242742a624d49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071a5b6069b8447bab0156fdec753c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:04<00:20,  4.09s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:06<00:13,  3.26s/it]\u001b[AYour max_length is set to 60, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "\n",
      " 50%|█████     | 3/6 [00:07<00:06,  2.27s/it]\u001b[AYour max_length is set to 60, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:08<00:03,  1.64s/it]\u001b[AYour max_length is set to 60, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.30s/it]\u001b[AYour max_length is set to 60, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Persona saved to output/Hungry-Move-6603_persona.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Input your Reddit profile URL\n",
    "reddit_url = \"https://www.reddit.com/user/Hungry-Move-6603/\"  # Change this to any valid Reddit user\n",
    "username = extract_username_from_url(reddit_url)\n",
    "\n",
    "print(f\"Extracting data for: {username}\")\n",
    "reddit = init_reddit()\n",
    "posts, comments = scrape_user_data(username, reddit)\n",
    "\n",
    "print(\"Generating persona...\")\n",
    "persona = build_user_persona(posts, comments)\n",
    "\n",
    "filepath = save_persona(username, persona)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Z_vAMdVI7Cr6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
